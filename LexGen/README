The procedure generate-LANG-lexer takes a description, which is an
associative list of the form ((Identifier RegExp) ...), and generates
token reading code.

Each variant of generate-LANG-lexer also takes an optional second
argument, which can be a filename or an output port where the
generated output will be sent; it defaults to (current-output-port).

The generated code fragment has the nullary procedure scanner0 as
entry point.  The fragment assumes its context provides the following
procedures:
  scanChar()                       -- peeks at next char in input,
  consumeChar()                    -- moves input cursor,
  accept(Token)                    -- returns input token kind,
  resetAccumulator()               -- accumulated token reset to "",
  scannerError(ScannerErrorKind)   -- called on error inputs.

The generated fragment assumes the context provides the following
constant values for ScannerErrorKind: { errIllegalChar, errLexGenBug,
errIncompleteToken }, and language-dependent expressions for Token
(for Scheme, Token is '<name>; for Java and C, Token is z<name>).

The generated fragment may also assume the a constant value named EOF
that can be compared with the result of scanChar() to detect
end-of-input.

See regexp.sch for the actual syntax for regexps.  As best I can tell
from reading and experimentation, the data definitions are roughly:

;; An Identifier is a Symbol that when printed is a legal identifer
;; fragment for the target language.  (For example, using a sequence
;; of upper- and lower-case letters from the basic Latin alphabet.)

;; A RegExp is one of:
;; - Character                    -- literal
;; - [Listof RegExp]              -- catentation
;; - (cons '! [Listof RegExp])    -- alternation
;; - (list '* RegExp)             -- Kleene star
;; - (list '+ RegExp)             -- (+ R) is same as (R (* R))
